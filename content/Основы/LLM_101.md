# 2.1. LLM 101 для инженеров: токены, контекст, ограничения, галлюцинации

- **Last reviewed**: 2026-01-15
- **Уровень**: Basic

## Зачем эта страница

Чтобы у команды было общее понимание "как LLM видит задачу" и почему **контекст‑дисциплина** важнее "красоты промпта".

## Ключевые понятия

- **Токены**: стоимость и лимиты считаются не "символами", а токенами.
- **Контекст‑окно**: сколько модель может "держать в голове" одновременно.
- **Сессия vs контекст**:
  - *контекст* — что вы положили сейчас (файлы/логи/AC),
  - *usage токены сессии* — сколько вы уже потратили за разговор (не равно текущему контексту).
- **Галлюцинации**: модель может уверенно ошибаться при нехватке фактов/ограничений.

## Почему "галлюцинирует"

Практическая причина: модель оптимизирует правдоподобие текста, а не истинность.

Снижаем риск:

- давать факты/артефакты (файлы, AC, логи, примеры),
- требовать воспроизводимые проверки (tests/build/static),
- резать контекст до "минимально нужного".

## Контекст‑инжиниринг: "меньше, но точнее"

Рекомендации:

- **Не мусорить в контексте**: лучше 3 файла и AC, чем "всё репо".
- **Сжимать**: вместо 2000 строк логов — "top errors + 20 строк вокруг + подсказка где искать".
- **Фиксировать инварианты**: "не менять публичный API", "не трогать auth/db/crypto".
- **Ограничивать область**: "работаем только в папке X, файлы Y/Z".

## Золотое правило инженерии с LLM

**LLM пишет — тесты решают.**

Рекомендуемый цикл:

1. Spec/AC
2. Plan
3. Patch
4. Verify
5. Самопроверка по DoD/AC

## Связанные страницы

- [2.6 Промптинг и элиситация](Промптинг_Элиситация_RE.md)
- [4.1 Единый workflow](../Стандартный_Процесс/Спецификация_План_Реализация_Проверка_PR.md)
- [6.4 Safe prompting & redaction](../Безопасность_Соответствие/Безопасный_Промптинг_Редактирование.md)

